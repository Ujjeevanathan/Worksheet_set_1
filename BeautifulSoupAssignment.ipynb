{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Shqkj_uCKms"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
        "bs = BeautifulSoup(html, \"html.parser\")\n",
        "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
        "print('List all the header tags :', *titles, sep='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "html = urlopen('https://presidentofindia.nic.in/former-presidents.html')\n",
        "bs = BeautifulSoup(html, \"html.parser\")\n",
        "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
        "print('List all the Prime Minister tags :', *titles, sep='\\n\\n')"
      ],
      "metadata": {
        "id": "xucdrwY3CRRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "batsman = [team.text for team in soup.find_all('div', {'class': 'rankings-block__banner--name'})][:11]\n",
        "\n",
        "data = pd.DataFrame(batsman,columns=['batsman'])\n",
        "data"
      ],
      "metadata": {
        "id": "OJKjWBhYD2b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "teams = [team.text for team in soup.find_all('span', {'class': 'u-hide-phablet'})][:11]\n",
        "\n",
        "data = pd.DataFrame(teams,columns=['Country'])\n",
        "data"
      ],
      "metadata": {
        "id": "YobWHfbPH6Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "bowlers = [team.text for team in soup.find_all('div', {'class': 'rankings-block__banner--name'})][:11]\n",
        "\n",
        "data = pd.DataFrame(bowlers,columns=['bowlers'])\n",
        "data"
      ],
      "metadata": {
        "id": "8oHUP8APJTc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "batsman = [team.text for team in soup.find_all('div', {'class': 'rankings-block__banner--name'})][:11]\n",
        "\n",
        "data = pd.DataFrame(batsman,columns=['batsman'])"
      ],
      "metadata": {
        "id": "DHqNezE-T6Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "teams = [team.text for team in soup.find_all('span', {'class': 'u-hide-phablet'})][:11]\n",
        "\n",
        "data = pd.DataFrame(teams,columns=['Country'])\n",
        "data"
      ],
      "metadata": {
        "id": "zuO-XBkWUFpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "bowlers = [team.text for team in soup.find_all('div', {'class': 'rankings-block__banner--name'})][:11]\n",
        "\n",
        "data = pd.DataFrame(bowlers,columns=['bowlers'])\n",
        "data"
      ],
      "metadata": {
        "id": "mLc9B8TuUIPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "nbc_business = \"https://www.cnbc.com/world/?region=world\"\n",
        "res = requests.get(nbc_business)\n",
        "soup = BeautifulSoup(res.content, 'html.parser')\n",
        "\n",
        "headlines = soup.find_all('span',{'class':'tease-card__headline'})\n",
        "time = soup.find_all('span',{'class':'tease-card__time'})\n",
        "news = soup.find_all('a',{'class':'tease-card__headline'})\n",
        "\n",
        "data = pd.DataFrame({\"Headlines\":headlines,\"time\":time,\"news\":news})\n",
        "data"
      ],
      "metadata": {
        "id": "lW1TREP_Uzhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "journals = [journal.text for journal in soup.find_all('h2', {'class': 'sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg'})][:11]\n",
        "\n",
        "data = pd.DataFrame(journals,columns=['journals'])\n",
        "data"
      ],
      "metadata": {
        "id": "QGw8GNOTWTNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "authors = [author.text for author in soup.find_all('span', {'class': 'sc-1w3fpd7-0 dnCnAO'})][:11]\n",
        "\n",
        "data = pd.DataFrame(authors,columns=['authors'])\n",
        "data"
      ],
      "metadata": {
        "id": "0cl1Wwz7WbSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "dates = [date.text for date in soup.find_all('span', {'class': 'sc-1thf9ly-2 dvggWt'})][:11]\n",
        "\n",
        "data = pd.DataFrame(dates,columns=['Published Date'])\n",
        "data"
      ],
      "metadata": {
        "id": "Ld1MRVXUW_QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "#Used headers/agent because the request was timed out and asking for an agent.\n",
        "#Using following code we can fake the agent.\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
        "response = requests.get(\"https://www.zomato.com/bangalore/top-restaurants\",headers=headers)\n",
        "\n",
        "content = response.content\n",
        "soup = BeautifulSoup(content,\"html.parser\")\n",
        "\n",
        "top_rest = soup.find_all(\"div\",attrs={\"class\": \"bb0 collections-grid col-l-16\"})\n",
        "list_tr = top_rest[0].find_all(\"div\",attrs={\"class\": \"col-s-8 col-l-1by3\"})\n",
        "\n",
        "list_rest =[]\n",
        "for tr in list_tr:\n",
        "    dataframe ={}\n",
        "    dataframe[\"rest_name\"] = (tr.find(\"div\",attrs={\"class\": \"res_title zblack bold nowrap\"})).text.replace('\\n', ' ')\n",
        "    dataframe[\"rest_address\"] = (tr.find(\"div\",attrs={\"class\": \"nowrap grey-text fontsize5 ttupper\"})).text.replace('\\n', ' ')\n",
        "    dataframe[\"cuisine_type\"] = (tr.find(\"div\",attrs={\"class\":\"nowrap grey-text\"})).text.replace('\\n', ' ')\n",
        "    list_rest.append(dataframe)\n",
        "list_rest\n",
        "\n",
        "import pandas\n",
        "df = pandas.DataFrame(list_rest)\n",
        "df.to_csv(\"zomato_res.csv\",index=False)"
      ],
      "metadata": {
        "id": "hnCy32O-XOk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPXJT6hKYIam"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}